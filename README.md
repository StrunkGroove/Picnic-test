# Для старта
```nano .env```
```
POSTGRES_USER=your_username
POSTGRES_PASSWORD=your_password
POSTGRES_DB=your_database
POSTGRES_PORT=5432
POSTGRES_HOST=postgres

WEATHER_API_KEY=99ba78ee79a2a24bc507362c5288a81b
```

```docker-compose up --build```

Запустить тесты
```docker exec -it picnic-test-backend-1 bash```
```pytest tests/test_users.py```


# Возможные проблемы при масштабировании проекта

 - Ограничение на использование Weather API при увеличении числа пользователей
 - Множественные одинаковые запросы к Weather API из-за отсутсвия кеша
 - Злоупотребелние пользователями ендпоинтов
 - Отсутствие структуры


# Правильная архитектура проетка
 - Для обеспечения более высокой надежности рекомендуется использовать uvicorn + Nginx или Apache.
 - Добавить автоматический парсинг данных о погоде для всех городов с последующим сохранением в кеше необходим для преодоления ограничений на использование Weather API. Рассматривается также возможность внедрения прокси или использование нескольких серверов с различными IP для обеспечения полного охвата парсинга всех городов.
 - При интеграции данных о погоде в другие сервисы рекомендуется выделить процесс парсинга в отдельный микросервис. Однако, чтобы избежать постоянных запросов одних и тех же данных с наших серверов, целесообразно использовать ленивый кеш везде.
 - При огромном количестве пользователей целесообразно еще более тщательно провести декомпозицию на микросервисы. Одним из разумных шагов может быть выделение сервиса, отвечающего за регистрацию пользователей, в отдельный микросервис. Такое решение позволит удобно использовать данные о пользователях в других сервисах. Кроме того, мы можем эффективно масштабировать серверы в области, где происходит максимальная нагрузка (запись пользователей на пикники), так как они, вероятно, будут более частыми, чем операции регистрации.
